# deepseek-r1:7b
##############################
## Configuration for lsp-ai ##
##############################

[language-server.lsp-ai]
command = "lsp-ai"

[language-server.lsp-ai.config.memory]
file_store = { }

[language-server.lsp-ai.config.models.model1]
type = "ollama"
model = "deepseek-coder"

[language-server.lsp-ai.config.completion]
model = "model1"

[language-server.lsp-ai.config.completion.parameters]
max_context = 1024

[language-server.lsp-ai.config.completion.parameters.options]
num_predict = 64

#################################
## Configuration for languages ##
#################################

[[language]]
name = "rust"
language-servers = ["rust-analyzer", "lsp-ai"]
